{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Remove pathlib, only here to find correct paths.\n",
    "# import pathlib\n",
    "# print(pathlib.Path().absolute())\n",
    "\n",
    "# As we are writing in a seperate folder we need to add paths to the other modules not contained in the current system paths.\n",
    "import sys\n",
    "sys.path.insert(1,'/home/jetbot')\n",
    "sys.path.insert(1,'/home/jetbot/monodepth2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetson.utils.__init__.py\n",
      "jetson.inference.__init__.py\n"
     ]
    }
   ],
   "source": [
    "from jetson import utils, inference\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image as pil\n",
    "import cv2\n",
    "\n",
    "from jetbot import Camera, bgr8_to_jpeg, Robot\n",
    "\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not initialize camera.  Please see error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.3.0-py3.6.egg/jetbot/camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not read image from camera.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not read image from camera.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ed5a20ac530f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcamwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcamwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcamheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/traitlets/config/configurable.py\u001b[0m in \u001b[0;36minstance\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# Create and save the instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Now make sure that the instance will also be returned by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;31m# parent classes' _instance attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.3.0-py3.6.egg/jetbot/camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             raise RuntimeError(\n\u001b[0;32m---> 37\u001b[0;31m                 'Could not initialize camera.  Please see error trace.')\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not initialize camera.  Please see error trace."
     ]
    }
   ],
   "source": [
    "camwidth, camheight = 224, 224\n",
    "cam = Camera.instance(width=camwidth, height=camheight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(device)\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "normalize = transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value): # Preprocessing for camera format --> Network input format\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) #(x, i)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "'''transform = transforms.Compose([            #[1]\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=[0.485, 0.456, 0.406],                #[6]\n",
    " std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])'''\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with open('classes.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "camwidth, camheight = 224, 224\n",
    "cam = Camera.instance(width=camwidth, height=camheight)\n",
    "\n",
    "rob = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(change):\n",
    "    # global robot, prob_blocked\n",
    "    try:\n",
    "        x = change['new'] \n",
    "        x = preprocess(x)\n",
    "        out = model(x)\n",
    "\n",
    "        # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "        _, index = torch.max(out, 1)\n",
    "        if index in [967, 968, 504, 505]:\n",
    "            rob.forward(0.4)\n",
    "            time.sleep(0.5)\n",
    "            rob.stop()\n",
    "        pct = F.softmax(out, dim=1)[0] * 100\n",
    "        print(classes[index[0]], round(pct[index[0]].item(), 3))\n",
    "        time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        cam.stop()\n",
    "        print('Loop successfully ended.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update({'new': cam.value})\n",
    "cam.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, index = torch.max(out, 1)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "print(classes[index[0]], percentage[index[0]].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "print([(classes[idx], percentage[idx].item()) for idx in indices[0][:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudokode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeline:\n",
    "- Ta inn en gjenstand\n",
    "- Kjør rundt\n",
    "- Se etter samme gjenstand\n",
    "- Identifiser som samme gjenstand\n",
    "- Kjør bort til den\n",
    "\n",
    "\n",
    "Kode:\n",
    "\n",
    "Ta inn gjenstand, gjør estimering, lagre ID\n",
    "\n",
    "som del av update<cam.value> spesial funskjonen: konstant identifiser gjenstander.\n",
    "\n",
    "Hvis den gjetter samme id som er lagret, ovveride(break) og gå til oppsøkingsfunksjon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        img = pil.fromarray(cam.value.astype('uint8'),'RGB') #.rotate(180)\n",
    "        # img = Image.open(\"a.jpg\")\n",
    "        img_t = transform(img)\n",
    "        batch_t = torch.unsqueeze(img_t, 0).cuda()\n",
    "        out = model(batch_t)\n",
    "        \n",
    "        _, index = torch.max(out, 1)\n",
    "        percentage = F.softmax(out, dim=1)[0] * 100\n",
    "        print(classes[index[0]], percentage[index[0]].item())\n",
    "        time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        cam.stop()\n",
    "        print('Loop successfully ended.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-forsøk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "normalize = transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value): # Preprocessing for camera format --> Network input format\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) #(x, i)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = transform(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "transform = transforms.Compose([            #[1]\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=[0.485, 0.456, 0.406],                #[6]\n",
    " std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prep(cam_val):\n",
    "    global device, normalize\n",
    "    x = pil.fromarray(cam_val.astype('uint8'),'RGB')\n",
    "    x.show()\n",
    "    x = transform(x)\n",
    "    x = torch.unsqueeze(img_t, 0)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def update(change):\n",
    "    # global robot, prob_blocked\n",
    "    x = change['new'] \n",
    "    print(x.shape)\n",
    "    x = prep(x)\n",
    "    print(x.shape)\n",
    "    out = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    _, index = torch.max(out, 1)\n",
    "    pct = F.softmax(out, dim=1)[0] * 100\n",
    "    print(classes[index[0]], round(pct[index[0]].item(), 3))\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(change):\n",
    "    # global robot, prob_blocked\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    out = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    _, index = torch.max(out, 1)\n",
    "    pct = F.softmax(out, dim=1)[0] * 100\n",
    "    print(classes[index[0]], round(pct[index[0]].item(), 3))\n",
    "        \n",
    "    time.sleep(0.01)\n",
    "\n",
    "# update({'new': cam.value})\n",
    "# cam.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.unobserve(update, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
